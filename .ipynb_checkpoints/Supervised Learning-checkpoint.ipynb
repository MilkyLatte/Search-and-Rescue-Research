{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import json\n",
    "import copy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadMaps():\n",
    "    with open('maps1.json', 'r') as f:\n",
    "        a = json.load(f)\n",
    "    return copy.deepcopy(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "maps = loadMaps()\n",
    "\n",
    "print(maps[\"moves\"][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f2bf1ed8eb8>"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvqOYd8AAACTtJREFUeJzt3c2LXYUdxvHncZxkfAOhzcJm0kYa0UahBoYYCHSRuogvKN0p6EqYTYUYBNGlf4DWjZugqYKiCLoQsUioihViNGoU01EIYjEoxCqisRiJPl3MXQSbyT2Te86cOb9+PzAwNzmcPIT5zrn3znCvkwhATef0PQBAdwgcKIzAgcIIHCiMwIHCCBwojMCBwggcKIzAgcLO7eKka7w2M7qgi1O37sSGYewcqrWfftf3hJK+13f6ISc87rhOAp/RBbrGf+zi1K07cve2vieUtmn3G31PKOlA/t7oOO6iA4UROFAYgQOFEThQGIEDhRE4UBiBA4UROFAYgQOFEThQGIEDhRE4UBiBA4UROFAYgQOFEThQWKPAbe+0/ZHtI7bv7XoUgHaMDdz2lKSHJV0nabOkW21v7noYgMk1uYJvlXQkycdJfpD0tKSbu50FoA1NAl8v6dNTbh8d/RmAVa7Jiy6e7pUb/+dNxW3PS5qXpBmdP+EsAG1ocgU/KmnDKbdnJX3284OS7Ekyl2RuWmvb2gdgAk0Cf0vSZbYvtb1G0i2Snu92FoA2jL2LnuSk7TslvSRpStLeJIc7XwZgYo3e+CDJi5Je7HgLgJbxm2xAYQQOFEbgQGEEDhRG4EBhBA4URuBAYQQOFEbgQGEEDhRG4EBhBA4URuBAYQQOFEbgQGEEDhRG4EBhjV7RpbJNu9/oe8KyHPnLtr4nlDWk/9sTDzT7uuUKDhRG4EBhBA4URuBAYQQOFEbgQGEEDhRG4EBhBA4URuBAYQQOFEbgQGEEDhRG4EBhBA4URuBAYQQOFDY2cNt7bR+z/cFKDALQniZX8Mck7ex4B4AOjA08yWuSvlqBLQBaxmNwoLDWXlXV9rykeUma0fltnRbABFq7gifZk2Quydy01rZ1WgAT4C46UFiTH5M9JWm/pMttH7V9R/ezALRh7GPwJLeuxBAA7eMuOlAYgQOFEThQGIEDhRE4UBiBA4UROFAYgQOFEThQGIEDhRE4UBiBA4UROFAYgQOFEThQGIEDhRE4UBiBA4UROFAYgQOFEThQGIEDhRE4UBiBA4UROFAYgQOFEThQGIEDhRE4UBiBA4UROFAYgQOFEThQGIEDhY0N3PYG26/YXrB92PaulRgGYHLnNjjmpKS7k7xj+yJJb9vel+SfHW8DMKGxV/Aknyd5Z/T5t5IWJK3vehiAyS3rMbjtjZK2SDrQxRgA7WpyF12SZPtCSc9KuivJN6f5+3lJ85I0o/NbGwjg7DW6gtue1mLcTyZ57nTHJNmTZC7J3LTWtrkRwFlq8iy6JT0qaSHJg91PAtCWJlfw7ZJul7TD9qHRx/Ud7wLQgrGPwZO8LskrsAVAy/hNNqAwAgcKI3CgMAIHCiNwoDACBwojcKAwAgcKI3CgMAIHCiNwoDACBwojcKAwAgcKI3CgMAIHCiNwoLDGr6q6HGuuOEe/evyiLk7dutf2X9n3BKwSm3a/0feExr7Md42O4woOFEbgQGEEDhRG4EBhBA4URuBAYQQOFEbgQGEEDhRG4EBhBA4URuBAYQQOFEbgQGEEDhRG4EBhBA4UNjZw2zO237T9nu3Dtu9fiWEAJtfkJZtOSNqR5LjtaUmv2/5bkuG8vg3wf2ps4Eki6fjo5vToI12OAtCORo/BbU/ZPiTpmKR9SQ50OwtAGxoFnuTHJFdLmpW01fZVPz/G9rztg7YPfv/1923vBHAWlvUsepKvJb0qaedp/m5PkrkkczMXz7Q0D8AkmjyLvs72xaPPz5N0raQPux4GYHJNnkW/RNLjtqe0+A3hmSQvdDsLQBuaPIv+vqQtK7AFQMv4TTagMAIHCiNwoDACBwojcKAwAgcKI3CgMAIHCiNwoDACBwojcKAwAgcKI3CgMAIHCiNwoDACBwpr8oouy7ZxzXH99df/6OLUrfvt/iv7nrAsm3YP6+Xo//Ona/qe0Nhnf3DfExo78UCzrwOu4EBhBA4URuBAYQQOFEbgQGEEDhRG4EBhBA4URuBAYQQOFEbgQGEEDhRG4EBhBA4URuBAYQQOFEbgQGGNA7c9Zftd2y90OQhAe5ZzBd8laaGrIQDa1yhw27OSbpD0SLdzALSp6RX8IUn3SPqpwy0AWjY2cNs3SjqW5O0xx83bPmj74Bdf/tjaQABnr8kVfLukm2x/IulpSTtsP/Hzg5LsSTKXZG7dL6ZangngbIwNPMl9SWaTbJR0i6SXk9zW+TIAE+Pn4EBhy3pnkySvSnq1kyUAWscVHCiMwIHCCBwojMCBwggcKIzAgcIIHCiMwIHCCBwojMCBwggcKIzAgcIIHCiMwIHCCBwojMCBwggcKMxJ2j+p/YWkf7V82l9K+nfL5+zSkPYOaas0rL1dbf1NknXjDuok8C7YPphkru8dTQ1p75C2SsPa2/dW7qIDhRE4UNiQAt/T94BlGtLeIW2VhrW3162DeQwOYPmGdAUHsEyDCNz2Ttsf2T5i+96+95yJ7b22j9n+oO8t49jeYPsV2wu2D9ve1fempdiesf2m7fdGW+/ve1MTtqdsv2v7hT7+/VUfuO0pSQ9Luk7SZkm32t7c76ozekzSzr5HNHRS0t1Jfidpm6Q/r+L/2xOSdiT5vaSrJe20va3nTU3skrTQ1z++6gOXtFXSkSQfJ/lBi+9wenPPm5aU5DVJX/W9o4kknyd5Z/T5t1r8Qlzf76rTy6Ljo5vTo49V/QSS7VlJN0h6pK8NQwh8vaRPT7l9VKv0i3DIbG+UtEXSgX6XLG10d/eQpGOS9iVZtVtHHpJ0j6Sf+howhMB9mj9b1d+5h8b2hZKelXRXkm/63rOUJD8muVrSrKSttq/qe9NSbN8o6ViSt/vcMYTAj0racMrtWUmf9bSlHNvTWoz7ySTP9b2niSRfa/Fdblfzcx3bJd1k+xMtPqzcYfuJlR4xhMDfknSZ7Uttr5F0i6Tne95Ugm1LelTSQpIH+95zJrbX2b549Pl5kq6V9GG/q5aW5L4ks0k2avFr9uUkt630jlUfeJKTku6U9JIWnwR6JsnhflctzfZTkvZLutz2Udt39L3pDLZLul2LV5dDo4/r+x61hEskvWL7fS1+09+XpJcfPQ0Jv8kGFLbqr+AAzh6BA4UROFAYgQOFEThQGIEDhRE4UBiBA4X9F9oJ5cyusXx0AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(np.array(maps[\"maps\"][1]).reshape(5,5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(flattened):\n",
    "    for i in range(len(flattened)):\n",
    "        minimum = min(flattened)\n",
    "        maximum = max(flattened)\n",
    "        flattened[i] = (flattened[i]-minimum)/(maximum - minimum)\n",
    "        \n",
    "    return flattened\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.5, 0.5, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.5, 0.0, 0.0, 0.5, 0.0, 0.5, 0.75, 0.5, 0.5, 0.0, 0.0, 1.0, 1.0, 0.5, 0.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "normalized = []\n",
    "for i in maps[\"maps\"]:\n",
    "    normalized.append(normalize(i))\n",
    "print(normalized[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# newMaps = {\n",
    "#     \"maps\":[],\n",
    "#     \"moves\":[]\n",
    "# }\n",
    "\n",
    "# newMaps[\"maps\"] = normalized\n",
    "# newMaps[\"moves\"] = maps[\"moves\"]\n",
    "\n",
    "# def writeMaps(maps):\n",
    "#     with open('normalizedMaps.json', 'w') as f:\n",
    "#         a = json.dump(maps, f, separators=(',', ': '), indent=4)\n",
    "# writeMaps(newMaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f2dc48a79b0>"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvqOYd8AAACPRJREFUeJzt3c1rXQUexvHnmVhRsOhiuihNmbpQmSJMhVCELgrFRXxBtxZ0JcTFCBUE0V36D4gbFw1aHFAUQRdSHKRgiwiO2moVO1Eo4mCxkA7iSzdK9TeLeweK0/Se9J6Tk/PM9wOB3PZw+1Dyzbn35nLiqhKATH/oewCA7hA4EIzAgWAEDgQjcCAYgQPBCBwIRuBAMAIHgl3TxZ3aHszb47Zu3dr3hGjnzp3re0KsqvKkYzoJfEgeffTRvidEW1xc7HvC/zUeogPBCBwIRuBAMAIHghE4EIzAgWAEDgQjcCAYgQPBCBwIRuBAMAIHghE4EIzAgWAEDgQjcCBYo8Btz9v+0vYZ2091PQpAOyYGbntG0nOS7pa0U9J+2zu7HgZgek3O4Lslnamqr6rqF0mvSnqg21kA2tAk8G2Svrnk9tnxnwHY4JpcdPFyV278n6um2l6QtDD1IgCtaRL4WUnbL7k9K+nb3x9UVUuSlqRhXTYZSNbkIfpHkm6xfbPtayU9KOnNbmcBaMPEM3hVXbT9mKS3Jc1IOlxVpztfBmBqjX7xQVW9JemtjrcAaBnvZAOCETgQjMCBYAQOBCNwIBiBA8EIHAhG4EAwAgeCETgQjMCBYAQOBCNwIBiBA8EIHAhG4EAwAgeCNbqiS7LFxcW+J6zJ0PYOyZD+bw8dOtToOM7gQDACB4IROBCMwIFgBA4EI3AgGIEDwQgcCEbgQDACB4IROBCMwIFgBA4EI3AgGIEDwQgcCEbgQLCJgds+bHvF9ufrMQhAe5qcwV+UNN/xDgAdmBh4Vb0r6bt12AKgZTwHB4K1dlVV2wuSFtq6PwDTay3wqlqStCRJtqut+wVw9XiIDgRr8mOyVyS9L+k222dtP9L9LABtmPgQvar2r8cQAO3jIToQjMCBYAQOBCNwIBiBA8EIHAhG4EAwAgeCETgQjMCBYAQOBCNwIBiBA8EIHAhG4EAwAgeCETgQjMCBYAQOBCNwIBiBA8EIHAhG4EAwAgeCETgQjMCBYAQOBCNwIBiBA8EIHAhG4EAwAgeCETgQjMCBYBMDt73d9jHby7ZP2z6wHsMATO+aBsdclPREVX1se7Okk7aPVtU/O94GYEoTz+BVda6qPh5//pOkZUnbuh4GYHpreg5ue4ekOyR90MUYAO1q8hBdkmT7BkmvS3q8qn68zN8vSFpocRuAKTUK3PYmjeJ+uareuNwxVbUkaWl8fLW2EMBVa/IquiW9IGm5qp7pfhKAtjR5Dr5H0sOS9tk+Nf64p+NdAFow8SF6Vb0nyeuwBUDLeCcbEIzAgWAEDgQjcCAYgQPBCBwIRuBAMAIHghE4EIzAgWAEDgQjcCAYgQPBCBwIRuBAMAIHghE4EKzxVVXX4tZbb9XS0lIXd92648eP9z0BG8Ti4mLfE1rHGRwIRuBAMAIHghE4EIzAgWAEDgQjcCAYgQPBCBwIRuBAMAIHghE4EIzAgWAEDgQjcCAYgQPBCBwINjFw29fZ/tD2p7ZP2z64HsMATK/JJZt+lrSvqi7Y3iTpPdt/r6p/dLwNwJQmBl5VJenC+Oam8Ud1OQpAOxo9B7c9Y/uUpBVJR6vqg25nAWhDo8Cr6teq2iVpVtJu27f//hjbC7ZP2D7xww8/tL0TwFVY06voVfW9pOOS5i/zd0tVNVdVczfeeGNL8wBMo8mr6Fts3zT+/HpJd0n6outhAKbX5FX0rZL+ZntGo28Ir1XVkW5nAWhDk1fRP5N0xzpsAdAy3skGBCNwIBiBA8EIHAhG4EAwAgeCETgQjMCBYAQOBCNwIBiBA8EIHAhG4EAwAgeCETgQjMCBYE2u6LJmmzdv1t69e7u469YNZed/HTzI753oyugK4cMwNzfX6DjO4EAwAgeCETgQjMCBYAQOBCNwIBiBA8EIHAhG4EAwAgeCETgQjMCBYAQOBCNwIBiBA8EIHAhG4ECwxoHbnrH9ie0jXQ4C0J61nMEPSFruagiA9jUK3PaspHslPd/tHABtanoGf1bSk5J+63ALgJZNDNz2fZJWqurkhOMWbJ+wfeL8+fOtDQRw9ZqcwfdIut/215JelbTP9ku/P6iqlqpqrqrmtmzZ0vJMAFdjYuBV9XRVzVbVDkkPSnqnqh7qfBmAqfFzcCDYmn6zSVUdl3S8kyUAWscZHAhG4EAwAgeCETgQjMCBYAQOBCNwIBiBA8EIHAhG4EAwAgeCETgQjMCBYAQOBCNwIBiBA8EIHAjmqmr/Tu3zkv7V8t3+UdK/W77PLg1p75C2SsPa29XWP1XVxKubdhJ4F2yfqKq5vnc0NaS9Q9oqDWtv31t5iA4EI3Ag2JACX+p7wBoNae+QtkrD2tvr1sE8BwewdkM6gwNYo0EEbnve9pe2z9h+qu89V2L7sO0V25/3vWUS29ttH7O9bPu07QN9b1qN7etsf2j70/HWg31vasL2jO1PbB/p49/f8IHbnpH0nKS7Je2UtN/2zn5XXdGLkub7HtHQRUlPVNWfJd0p6a8b+P/2Z0n7quovknZJmrd9Z8+bmjggabmvf3zDBy5pt6QzVfVVVf2i0W84faDnTauqqnclfdf3jiaq6lxVfTz+/CeNvhC39bvq8mrkwvjmpvHHhn4ByfaspHslPd/XhiEEvk3SN5fcPqsN+kU4ZLZ3SLpD0gf9Llnd+OHuKUkrko5W1YbdOvaspCcl/dbXgCEE7sv82Yb+zj00tm+Q9Lqkx6vqx773rKaqfq2qXZJmJe22fXvfm1Zj+z5JK1V1ss8dQwj8rKTtl9yelfRtT1vi2N6kUdwvV9Ubfe9poqq+1+i33G7k1zr2SLrf9tcaPa3cZ/ul9R4xhMA/knSL7ZttXyvpQUlv9rwpgm1LekHSclU90/eeK7G9xfZN48+vl3SXpC/6XbW6qnq6qmaraodGX7PvVNVD671jwwdeVRclPSbpbY1eBHqtqk73u2p1tl+R9L6k22yftf1I35uuYI+khzU6u5waf9zT96hVbJV0zPZnGn3TP1pVvfzoaUh4JxsQbMOfwQFcPQIHghE4EIzAgWAEDgQjcCAYgQPBCBwI9h9L480UtQgv7AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import cv2\n",
    "npMaps = np.array(maps[\"maps\"])\n",
    "scaler = MinMaxScaler()\n",
    "hey = scaler.fit_transform(npMaps[0].reshape(5,5))\n",
    "\n",
    "plt.imshow(np.array(normalized[0]).reshape(5,5),cmap='gist_gray')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 1.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " ...\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/milkylatte/anaconda3/envs/tf/lib/python3.5/site-packages/sklearn/preprocessing/_encoders.py:363: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "npSolution = np.array(maps[\"moves\"]).reshape(len(maps[\"moves\"]), 1)\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "encoded = onehot_encoder.fit_transform(npSolution)\n",
    "\n",
    "print(encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(np.array(normalized), encoded, test_size=0.3, random_state = 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f2dc485d5c0>"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[3].reshape(5,5), cmap=\"gist_gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = tf.placeholder(tf.float32, shape=[None, 400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# W = tf.Variable(tf.zeros([400, 4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b = tf.Variable(tf.zeros([4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = tf.matmul(x, W) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_true = tf.placeholder(tf.float32, [None, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_true, logits=y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = optimizer.minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tf.Session() as sess:\n",
    "#     sess.run(init)\n",
    "    \n",
    "#     for step in range(10000):\n",
    "#         i = np.random.randint(0, len(X_train)-100)\n",
    "#         sess.run(train, feed_dict={x: X_train[i:i+100], y_true: y_train[i:i+100]})\n",
    "        \n",
    "#     matches = tf.equal(tf.argmax(y, 1), tf.argmax(y_true, 1))\n",
    "#     acc = tf.reduce_mean(tf.cast(matches, tf.float32))\n",
    "#     print(sess.run(acc, feed_dict={x:X_test, y_true: y_test}))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(shape):\n",
    "    init_random_dist = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(init_random_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_bias(shape):\n",
    "    init_bias_vals = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(init_bias_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(x, W):\n",
    "    # x --> [batch, H, W, Channels]\n",
    "    # W --> [filter H, filter W, Channels IN, Channels OUT]\n",
    "    \n",
    "    return tf.nn.conv2d(x, W, strides=[1,1,1,1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_pool_2by2(x):\n",
    "    # x --> [batch, h, w, c]\n",
    "    return tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_layer(input_x, shape):\n",
    "    W = init_weights(shape)\n",
    "    b = init_bias([shape[3]])\n",
    "    return tf.nn.relu(conv2d(input_x, W)+b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_full_layer(input_layer, size):\n",
    "    input_size = int(input_layer.get_shape()[1])\n",
    "    W = init_weights([input_size, size])\n",
    "    b = init_bias([size])\n",
    "    return tf.matmul(input_layer, W) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, 25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = tf.placeholder(tf.float32,shape=[None, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_image = tf.reshape(x, [-1,5,5,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "convo_1 = convolutional_layer(x_image, shape=[5,5,1,25])\n",
    "#convo_1_pooling = max_pool_2by2(convo_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "convo_2 = convolutional_layer(convo_1, shape=[5,5,25,10])\n",
    "# convo_2_pooling = max_pool_2by2(convo_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "convo_2_flat = tf.reshape(convo_2,[-1,5*5*10])\n",
    "full_layer_one = tf.nn.relu(normal_full_layer(convo_2_flat, 1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "hold_prob = tf.placeholder(tf.float32)\n",
    "full_one_dropout = tf.nn.dropout(full_layer_one, keep_prob=hold_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = normal_full_layer(full_one_dropout, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_true, logits=y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.01)\n",
    "train = optimizer.minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tf.Session() as sess:\n",
    "#     sess.run(init)\n",
    "    \n",
    "#     for step in range(10000):\n",
    "#         i = np.random.randint(0, len(X_train)-100)\n",
    "#         sess.run(train, feed_dict={x: X_train[i:i+100], y_true: y_train[i:i+100]})\n",
    "        \n",
    "#     matches = tf.equal(tf.argmax(y, 1), tf.argmax(y_true, 1))\n",
    "#     acc = tf.reduce_mean(tf.cast(matches, tf.float32))\n",
    "#     print(sess.run(acc, feed_dict={x:X_test, y_true: y_test}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ON STEP: 0\n",
      "ACCURACY: \n",
      "0.24233717\n",
      "ON STEP: 100\n",
      "ACCURACY: \n",
      "0.29789272\n",
      "ON STEP: 200\n",
      "ACCURACY: \n",
      "0.3151341\n",
      "ON STEP: 300\n",
      "ACCURACY: \n",
      "0.3400383\n",
      "ON STEP: 400\n",
      "ACCURACY: \n",
      "0.3381226\n",
      "ON STEP: 500\n",
      "ACCURACY: \n",
      "0.33333334\n",
      "ON STEP: 600\n",
      "ACCURACY: \n",
      "0.33524904\n",
      "ON STEP: 700\n",
      "ACCURACY: \n",
      "0.34099618\n",
      "ON STEP: 800\n",
      "ACCURACY: \n",
      "0.33908045\n",
      "ON STEP: 900\n",
      "ACCURACY: \n",
      "0.34291187\n",
      "ON STEP: 1000\n",
      "ACCURACY: \n",
      "0.3342912\n",
      "ON STEP: 1100\n",
      "ACCURACY: \n",
      "0.33620688\n",
      "ON STEP: 1200\n",
      "ACCURACY: \n",
      "0.33237547\n",
      "ON STEP: 1300\n",
      "ACCURACY: \n",
      "0.3381226\n",
      "ON STEP: 1400\n",
      "ACCURACY: \n",
      "0.3381226\n",
      "ON STEP: 1500\n",
      "ACCURACY: \n",
      "0.33620688\n",
      "ON STEP: 1600\n",
      "ACCURACY: \n",
      "0.34578544\n",
      "ON STEP: 1700\n",
      "ACCURACY: \n",
      "0.33908045\n",
      "ON STEP: 1800\n",
      "ACCURACY: \n",
      "0.33908045\n",
      "ON STEP: 1900\n",
      "ACCURACY: \n",
      "0.3275862\n",
      "ON STEP: 2000\n",
      "ACCURACY: \n",
      "0.34099618\n",
      "ON STEP: 2100\n",
      "ACCURACY: \n",
      "0.34099618\n",
      "ON STEP: 2200\n",
      "ACCURACY: \n",
      "0.3381226\n",
      "ON STEP: 2300\n",
      "ACCURACY: \n",
      "0.34386975\n",
      "ON STEP: 2400\n",
      "ACCURACY: \n",
      "0.34578544\n",
      "ON STEP: 2500\n",
      "ACCURACY: \n",
      "0.33141762\n",
      "ON STEP: 2600\n",
      "ACCURACY: \n",
      "0.34099618\n",
      "ON STEP: 2700\n",
      "ACCURACY: \n",
      "0.3400383\n",
      "ON STEP: 2800\n",
      "ACCURACY: \n",
      "0.34386975\n",
      "ON STEP: 2900\n",
      "ACCURACY: \n",
      "0.32950193\n",
      "ON STEP: 3000\n",
      "ACCURACY: \n",
      "0.33333334\n",
      "ON STEP: 3100\n",
      "ACCURACY: \n",
      "0.348659\n",
      "ON STEP: 3200\n",
      "ACCURACY: \n",
      "0.33620688\n",
      "ON STEP: 3300\n",
      "ACCURACY: \n",
      "0.33908045\n",
      "ON STEP: 3400\n",
      "ACCURACY: \n",
      "0.33237547\n",
      "ON STEP: 3500\n",
      "ACCURACY: \n",
      "0.3400383\n",
      "ON STEP: 3600\n",
      "ACCURACY: \n",
      "0.34291187\n",
      "ON STEP: 3700\n",
      "ACCURACY: \n",
      "0.33620688\n",
      "ON STEP: 3800\n",
      "ACCURACY: \n",
      "0.3400383\n",
      "ON STEP: 3900\n",
      "ACCURACY: \n",
      "0.3448276\n",
      "ON STEP: 4000\n",
      "ACCURACY: \n",
      "0.33620688\n",
      "ON STEP: 4100\n",
      "ACCURACY: \n",
      "0.3505747\n",
      "ON STEP: 4200\n",
      "ACCURACY: \n",
      "0.3467433\n",
      "ON STEP: 4300\n",
      "ACCURACY: \n",
      "0.34578544\n",
      "ON STEP: 4400\n",
      "ACCURACY: \n",
      "0.35153258\n",
      "ON STEP: 4500\n",
      "ACCURACY: \n",
      "0.34291187\n",
      "ON STEP: 4600\n",
      "ACCURACY: \n",
      "0.3467433\n",
      "ON STEP: 4700\n",
      "ACCURACY: \n",
      "0.34195402\n",
      "ON STEP: 4800\n",
      "ACCURACY: \n",
      "0.34578544\n",
      "ON STEP: 4900\n",
      "ACCURACY: \n",
      "0.34386975\n",
      "ON STEP: 5000\n",
      "ACCURACY: \n",
      "0.34195402\n",
      "ON STEP: 5100\n",
      "ACCURACY: \n",
      "0.34099618\n",
      "ON STEP: 5200\n",
      "ACCURACY: \n",
      "0.35344827\n",
      "ON STEP: 5300\n",
      "ACCURACY: \n",
      "0.35249043\n",
      "ON STEP: 5400\n",
      "ACCURACY: \n",
      "0.34770116\n",
      "ON STEP: 5500\n",
      "ACCURACY: \n",
      "0.35153258\n",
      "ON STEP: 5600\n",
      "ACCURACY: \n",
      "0.35153258\n",
      "ON STEP: 5700\n",
      "ACCURACY: \n",
      "0.3467433\n",
      "ON STEP: 5800\n",
      "ACCURACY: \n",
      "0.3400383\n",
      "ON STEP: 5900\n",
      "ACCURACY: \n",
      "0.33716476\n",
      "ON STEP: 6000\n",
      "ACCURACY: \n",
      "0.36398467\n",
      "ON STEP: 6100\n",
      "ACCURACY: \n",
      "0.33908045\n",
      "ON STEP: 6200\n",
      "ACCURACY: \n",
      "0.3505747\n",
      "ON STEP: 6300\n",
      "ACCURACY: \n",
      "0.33524904\n",
      "ON STEP: 6400\n",
      "ACCURACY: \n",
      "0.33908045\n",
      "ON STEP: 6500\n",
      "ACCURACY: \n",
      "0.33333334\n",
      "ON STEP: 6600\n",
      "ACCURACY: \n",
      "0.3448276\n",
      "ON STEP: 6700\n",
      "ACCURACY: \n",
      "0.34770116\n",
      "ON STEP: 6800\n",
      "ACCURACY: \n",
      "0.34099618\n",
      "ON STEP: 6900\n",
      "ACCURACY: \n",
      "0.34195402\n",
      "ON STEP: 7000\n",
      "ACCURACY: \n",
      "0.33620688\n",
      "ON STEP: 7100\n",
      "ACCURACY: \n",
      "0.33908045\n",
      "ON STEP: 7200\n",
      "ACCURACY: \n",
      "0.33908045\n",
      "ON STEP: 7300\n",
      "ACCURACY: \n",
      "0.33716476\n",
      "ON STEP: 7400\n",
      "ACCURACY: \n",
      "0.3448276\n",
      "ON STEP: 7500\n",
      "ACCURACY: \n",
      "0.3448276\n",
      "ON STEP: 7600\n",
      "ACCURACY: \n",
      "0.34578544\n",
      "ON STEP: 7700\n",
      "ACCURACY: \n",
      "0.34291187\n",
      "ON STEP: 7800\n",
      "ACCURACY: \n",
      "0.3448276\n",
      "ON STEP: 7900\n",
      "ACCURACY: \n",
      "0.3400383\n",
      "ON STEP: 8000\n",
      "ACCURACY: \n",
      "0.34386975\n",
      "ON STEP: 8100\n",
      "ACCURACY: \n",
      "0.33524904\n",
      "ON STEP: 8200\n",
      "ACCURACY: \n",
      "0.34770116\n",
      "ON STEP: 8300\n",
      "ACCURACY: \n",
      "0.3467433\n",
      "ON STEP: 8400\n",
      "ACCURACY: \n",
      "0.34961686\n",
      "ON STEP: 8500\n",
      "ACCURACY: \n",
      "0.34770116\n",
      "ON STEP: 8600\n",
      "ACCURACY: \n",
      "0.36015326\n",
      "ON STEP: 8700\n",
      "ACCURACY: \n",
      "0.34770116\n",
      "ON STEP: 8800\n",
      "ACCURACY: \n",
      "0.35153258\n",
      "ON STEP: 8900\n",
      "ACCURACY: \n",
      "0.34961686\n",
      "ON STEP: 9000\n",
      "ACCURACY: \n",
      "0.3467433\n",
      "ON STEP: 9100\n",
      "ACCURACY: \n",
      "0.34386975\n",
      "ON STEP: 9200\n",
      "ACCURACY: \n",
      "0.35249043\n",
      "ON STEP: 9300\n",
      "ACCURACY: \n",
      "0.35249043\n",
      "ON STEP: 9400\n",
      "ACCURACY: \n",
      "0.34291187\n",
      "ON STEP: 9500\n",
      "ACCURACY: \n",
      "0.34961686\n",
      "ON STEP: 9600\n",
      "ACCURACY: \n",
      "0.3448276\n",
      "ON STEP: 9700\n",
      "ACCURACY: \n",
      "0.3400383\n",
      "ON STEP: 9800\n",
      "ACCURACY: \n",
      "0.3505747\n",
      "ON STEP: 9900\n",
      "ACCURACY: \n",
      "0.35153258\n"
     ]
    }
   ],
   "source": [
    "steps = 10000\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for j in range(steps):\n",
    "        i = np.random.randint(0, len(X_train)-1000)\n",
    "\n",
    "        sess.run(train, feed_dict={x:X_train[i:i+1000], y_true:y_train[i:i+1000], hold_prob:0.5})\n",
    "        if j%100 == 0:\n",
    "            print(\"ON STEP: {}\".format(j))\n",
    "            print(\"ACCURACY: \")\n",
    "            \n",
    "            matches = tf.equal(tf.argmax(y_pred, 1), tf.argmax(y_true, 1))\n",
    "            acc = tf.reduce_mean(tf.cast(matches, tf.float32))\n",
    "            print(sess.run(acc, feed_dict={x:X_test[:10000], y_true:y_test[:10000], hold_prob:1.0}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
